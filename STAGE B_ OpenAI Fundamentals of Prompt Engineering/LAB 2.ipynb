{"cells":[{"source":"In this lab session, we will dive into practical exercises using the OpenAI library and explore the essentials of prompt engineering.","metadata":{},"cell_type":"markdown","id":"d3b346a8-6b21-4893-9909-69d364a2521a"},{"source":"import openai\nimport os\nimport IPython\nfrom dotenv import load_dotenv","metadata":{"executionCancelledAt":null,"executionTime":1026,"lastExecutedAt":1716996085656,"lastExecutedByKernel":"0c23dd08-620d-4661-b77c-ef890c83f493","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import openai\nimport os\nimport IPython\nfrom dotenv import load_dotenv"},"cell_type":"code","id":"3ea39fb2-0abe-4e02-8f89-50a6c4641cb4","outputs":[],"execution_count":1},{"source":"Firstly we will import the required libraries. the os module, which is a standard Python module providing a way to interact with the operating system. It's often used for tasks like working with file paths, environment variables, and executing system commands.\n\nIPython is an enhanced interactive Python interpreter. It provides additional features and tools for interactive computing, making it a popular choice for interactive development and data exploration.\n\nThe dotenv module is commonly used for loading environment variables from a file named \".env\" into the environment. This is useful for keeping sensitive information, such as API keys, out of the codebase and in a separate configuration file.","metadata":{},"cell_type":"markdown","id":"b6c1f607-03d0-418e-9b58-e2df43f1a00d"},{"source":"load_dotenv()\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")","metadata":{"executionCancelledAt":null,"executionTime":24,"lastExecutedAt":1716996199727,"lastExecutedByKernel":"0c23dd08-620d-4661-b77c-ef890c83f493","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"load_dotenv()\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")"},"cell_type":"code","id":"6940fae0-d0e6-471d-abcb-cbb8ddc5a19c","outputs":[],"execution_count":3},{"source":"We run the load_dotenv() function, which is typically used to load environment variables from a file named \".env\" into the environment. This is a common practice in Python projects to keep sensitive information, such as API keys or configuration parameters, separate from the codebase. By loading environment variables, the code can access these values without explicitly storing them in the source code. \n\nThen retrieve the value of the environment variable named “OPENAI_API_KEY” using the os.getenv() function and assign it to the api_key attribute of the openai module. the OpenAI library requires an API key for authentication, and the key is expected to be stored as an environment variable.\n\nNote that <s> and </s> are special tokens for beginning of string (BOS) and end of string (EOS) while [INST] and [/INST] are regular strings.","metadata":{},"cell_type":"markdown","id":"b3c51006-1e83-4dd8-93eb-8db67fc3124e"},{"source":"def set_open_params(\n    model=\"gpt-3.5-turbo-instruct\",\n    temperature=0.7,\n    max_tokens=256,\n    top_p=1,\n    frequency_penalty=0,\n    presence_penalty=0,  \n):\n    \"\"\"set openai parameter\"\"\"\n    openai_params = {}    \n\n    openai_params['model'] = model\n    openai_params['temperature'] = temperature\n    openai_params['max_tokens'] = max_tokens\n    openai_params['top_p'] = top_p\n    openai_params['frequency_penalty'] = frequency_penalty\n    openai_params['presence_penalty'] = presence_penalty\n    return openai_params\n","metadata":{"executionCancelledAt":null,"executionTime":11,"lastExecutedAt":1716996307624,"lastExecutedByKernel":"0c23dd08-620d-4661-b77c-ef890c83f493","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def set_open_params(\n    model=\"gpt-3.5-turbo-instruct\",\n    temperature=0.7,\n    max_tokens=256,\n    top_p=1,\n    frequency_penalty=0,\n    presence_penalty=0,  \n):\n    \"\"\"set openai parameter\"\"\"\n    openai_params = {}    \n\n    openai_params['model'] = model\n    openai_params['temperature'] = temperature\n    openai_params['max_tokens'] = max_tokens\n    openai_params['top_p'] = top_p\n    openai_params['frequency_penalty'] = frequency_penalty\n    openai_params['presence_penalty'] = presence_penalty\n    return openai_params\n\ndef get_completion(params, prompt):\n    \"\"\"Get completion from openai api\"\"\"\n    response = openai.Completion.create(\n        engine = params['model'],\n        prompt = prompt,\n        temperature = params['temperature'],\n        max_tokens = params['max_tokens'],\n        top_p = params['top_p'],\n        frequency_penalty = params['frequency_penalty'],\n        presence_penalty = params['presence_penalty'],\n    )\n    return response"},"cell_type":"code","id":"a46ea994-aa9e-4a07-ba0d-6f5885d054a4","outputs":[],"execution_count":4},{"source":"Then create a function that allows the user to customize the parameters used when making requests to OpenAI’s models, providing flexibility in configuring the behaviour of the model outputs. The user can either use the default values or provide specific values for the parameters they want to customize.","metadata":{},"cell_type":"markdown","id":"89fc9e11-9003-46e4-b314-409f20b65b97"},{"source":"def get_completion(params, prompt):\n    \"\"\"Get completion from openai api\"\"\"\n    response = openai.Completion.create(\n        engine = params['model'],\n        prompt = prompt,\n        temperature = params['temperature'],\n        max_tokens = params['max_tokens'],\n        top_p = params['top_p'],\n        frequency_penalty = params['frequency_penalty'],\n        presence_penalty = params['presence_penalty'],\n    )\n    return response","metadata":{"executionCancelledAt":null,"executionTime":12,"lastExecutedAt":1716996378620,"lastExecutedByKernel":"0c23dd08-620d-4661-b77c-ef890c83f493","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def get_completion(params, prompt):\n    \"\"\"Get completion from openai api\"\"\"\n    response = openai.Completion.create(\n        engine = params['model'],\n        prompt = prompt,\n        temperature = params['temperature'],\n        max_tokens = params['max_tokens'],\n        top_p = params['top_p'],\n        frequency_penalty = params['frequency_penalty'],\n        presence_penalty = params['presence_penalty'],\n    )\n    return response"},"cell_type":"code","id":"997d13c2-d47b-449e-bde4-bc314761a43b","outputs":[],"execution_count":5},{"source":"Also, define another function, get_completion which acts as a wrapper around the OpenAI API’s completion generation functionality. The function takes a set of parameters and a prompt, makes a request to the OpenAI API and returns the response object containing the generated completion.","metadata":{},"cell_type":"markdown","id":"98bb4044-5c62-4c4c-8e86-060e2f1beff4"},{"source":"params = set_open_params()\n\nprompt = \"Roses are\"\n\nresponse = get_completion(params, prompt)","metadata":{"executionCancelledAt":null,"executionTime":2242,"lastExecutedAt":1716996428344,"lastExecutedByKernel":"0c23dd08-620d-4661-b77c-ef890c83f493","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"params = set_open_params()\n\nprompt = \"Roses are\"\n\nresponse = get_completion(params, prompt)"},"cell_type":"code","id":"2c4f3a17-94d8-4397-9f2e-28156eb0c797","outputs":[],"execution_count":6},{"source":"response.choices[0].text","metadata":{"executionCancelledAt":null,"executionTime":12,"lastExecutedAt":1716996437411,"lastExecutedByKernel":"0c23dd08-620d-4661-b77c-ef890c83f493","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"response.choices[0].text"},"cell_type":"code","id":"88518575-1f7f-4d08-949b-fae70a63935f","outputs":[{"output_type":"execute_result","data":{"text/plain":"\" red\\nViolets are blue\\nI love you more\\nThan words can express, it's true\\n\\nYou are my heart\\nMy everything, my all\\nWithout you by my side\\nI would surely fall\\n\\nYour love is like a rose\\nBeautiful, delicate and pure\\nI am grateful every day\\nThat it's me you adore\\n\\nI promise to always love you\\nThrough the highs and lows\\nFor you are my forever\\nMy love, my rose.\""},"metadata":{},"execution_count":7}],"execution_count":7},{"source":"IPython.display.Markdown(response.choices[0].text)","metadata":{"executionCancelledAt":null,"executionTime":12,"lastExecutedAt":1716996455610,"lastExecutedByKernel":"0c23dd08-620d-4661-b77c-ef890c83f493","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"IPython.display.Markdown(response.choices[0].text)"},"cell_type":"code","id":"12a563fe-aedd-41de-8d14-8628af7fdf67","outputs":[{"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":" red\nViolets are blue\nI love you more\nThan words can express, it's true\n\nYou are my heart\nMy everything, my all\nWithout you by my side\nI would surely fall\n\nYour love is like a rose\nBeautiful, delicate and pure\nI am grateful every day\nThat it's me you adore\n\nI promise to always love you\nThrough the highs and lows\nFor you are my forever\nMy love, my rose."},"metadata":{},"execution_count":8}],"execution_count":8},{"source":"Just for a simple example, setup the OpenAI parameters, define a prompt, generate a completion using the OpenAI API and then display the generated text using Markdown formatting in an IPython environment.The specific content of the generated text depends on the OpenAI model, the parameters, and the provided prompt.\n\nIn the resources below are examples of how to use the OpenAI api and models to perform specific tasks.","metadata":{},"cell_type":"markdown","id":"fd28e006-5f69-4265-a642-87bfca48e703"},{"source":"params = set_open_params(temperature=0)\nprompt = \"Roses are\"\nresponse = get_completion(params, prompt)\nIPython.display.Markdown(response.choices[0].text)","metadata":{"executionCancelledAt":null,"executionTime":3130,"lastExecutedAt":1716996478373,"lastExecutedByKernel":"0c23dd08-620d-4661-b77c-ef890c83f493","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"params = set_open_params(temperature=0)\nprompt = \"Roses are\"\nresponse = get_completion(params, prompt)\nIPython.display.Markdown(response.choices[0].text)"},"cell_type":"code","id":"59e8ebc2-b404-4320-85c6-dd53f264a77a","outputs":[{"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":" red, violets are blue\nSugar is sweet, and so are you\nBut the roses wilt, and the violets fade\nBut my love for you will never degrade\n\nYou are my sunshine on a cloudy day\nMy guiding light when I lose my way\nWith you by my side, I can conquer all\nTogether we stand, we will never fall\n\nYour smile brightens up my darkest night\nYour touch fills me with pure delight\nI am grateful for every moment spent\nWith you, my love, my heart is content\n\nI promise to love you, through thick and thin\nTo be your rock, your shelter, your kin\nI'll hold your hand, and never let go\nTogether we'll face whatever life may throw\n\nSo here's my heart, my love, my all\nWith you, I'll stand tall, I'll never fall\nRoses may wither, and violets may die\nBut my love for you will never say goodbye."},"metadata":{},"execution_count":9}],"execution_count":9},{"source":"### Text Summarization\n\nThis code snippet shows how to use OpenAI API to summarize a long sentence or paragraph passed in as prompt with a specific instruction appended to it.","metadata":{},"cell_type":"markdown","id":"62655ff9-8fb1-4d02-9080-8ca04638cb55"},{"source":"params = set_open_params()\nprompt = \"\"\"Keras is a deep learning API written in Python that runs on top of TensorFlow. \n    It is quite popular among deep learning users because of its ease of use. \n    TensorFlow is an end-to-end open-source deep learning framework developed and maintained by Google. \n    Similar to Numpy, TensorFlow allows for mathematical computations and manipulation between numerical tensors, runs on CPUs, GPUs, and TPUs. \n    Keras was incorporated in TensorFlow 2.0 (the recent version) as tf.keras (high-level API) and can run on the aforementioned hardwares. \n    TensorFlow also allows for low-level operations with the TensorFlow Core API. \n\n    Explain the above in one sentence:\"\"\"\nresponse = get_completion(params, prompt)\nIPython.display.Markdown(response.choices[0].text)","metadata":{"executionCancelledAt":null,"executionTime":1246,"lastExecutedAt":1716996613029,"lastExecutedByKernel":"0c23dd08-620d-4661-b77c-ef890c83f493","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"params = set_open_params()\nprompt = \"\"\"Keras is a deep learning API written in Python that runs on top of TensorFlow. \n    It is quite popular among deep learning users because of its ease of use. \n    TensorFlow is an end-to-end open-source deep learning framework developed and maintained by Google. \n    Similar to Numpy, TensorFlow allows for mathematical computations and manipulation between numerical tensors, runs on CPUs, GPUs, and TPUs. \n    Keras was incorporated in TensorFlow 2.0 (the recent version) as tf.keras (high-level API) and can run on the aforementioned hardwares. \n    TensorFlow also allows for low-level operations with the TensorFlow Core API. \n\n    Explain the above in one sentence:\"\"\"\nresponse = get_completion(params, prompt)\nIPython.display.Markdown(response.choices[0].text)"},"cell_type":"code","id":"bfecc001-fd0d-4071-8156-2639ac9f7a9b","outputs":[{"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\nKeras is an easy-to-use deep learning API written in Python that runs on top of TensorFlow, an open-source deep learning framework that enables mathematical computations and manipulation between numerical tensors on CPUs, GPUs, and TPUs."},"metadata":{},"execution_count":10}],"execution_count":10},{"source":"prompt = \"\"\"Answer the question based on the context below. Keep the answer short and concise. Respond \"Unsure about answer\" if not sure about the answer.\n\nContext: The Avengers were a team of extraordinary individuals, with either superpowers or other special characteristics. Though primarily affiliated with the interests of the United States of America, the group's purpose was to protect global stability from inner or extraterrestrial threats. The Avengers were first assembled by S.H.I.E.L.D. as a result of the Avengers Initiative, when Loki invaded Earth with his Chitauri army. The team, consisting of Iron Man, Captain America, Hulk, Thor, Black Widow and Hawkeye defeated Loki and went their separate ways for a while.\n\nQuestion: Why were the Avengers formed?\n\nAnswer:\"\"\"\n\nresponse = get_completion(params, prompt)\nIPython.display.Markdown(response.choices[0].text)","metadata":{},"cell_type":"code","id":"3c27d5e3-5ca6-4343-b74d-5226a8218100","outputs":[],"execution_count":null},{"source":"### Question Answering\n\nThis code snippet uses the OpenAI model to automatically generate an answer to the question “Why were the Avengers formed?” based on the provided context. The result is then displayed in Markdown format.","metadata":{},"cell_type":"markdown","id":"0152ae0e-d0c7-4c3b-a1e3-f818c0801070"},{"source":"prompt = \"\"\"Answer the question based on the context below. Keep the answer short and concise. Respond \"Unsure about answer\" if not sure about the answer.\n\nContext: The Avengers were a team of extraordinary individuals, with either superpowers or other special characteristics. Though primarily affiliated with the interests of the United States of America, the group's purpose was to protect global stability from inner or extraterrestrial threats. The Avengers were first assembled by S.H.I.E.L.D. as a result of the Avengers Initiative, when Loki invaded Earth with his Chitauri army. The team, consisting of Iron Man, Captain America, Hulk, Thor, Black Widow and Hawkeye defeated Loki and went their separate ways for a while.\n\nQuestion: Why were the Avengers formed?\n\nAnswer:\"\"\"\n\nresponse = get_completion(params, prompt)\nIPython.display.Markdown(response.choices[0].text)","metadata":{"executionCancelledAt":null,"executionTime":532,"lastExecutedAt":1716996695448,"lastExecutedByKernel":"0c23dd08-620d-4661-b77c-ef890c83f493","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"prompt = \"\"\"Answer the question based on the context below. Keep the answer short and concise. Respond \"Unsure about answer\" if not sure about the answer.\n\nContext: The Avengers were a team of extraordinary individuals, with either superpowers or other special characteristics. Though primarily affiliated with the interests of the United States of America, the group's purpose was to protect global stability from inner or extraterrestrial threats. The Avengers were first assembled by S.H.I.E.L.D. as a result of the Avengers Initiative, when Loki invaded Earth with his Chitauri army. The team, consisting of Iron Man, Captain America, Hulk, Thor, Black Widow and Hawkeye defeated Loki and went their separate ways for a while.\n\nQuestion: Why were the Avengers formed?\n\nAnswer:\"\"\"\n\nresponse = get_completion(params, prompt)\nIPython.display.Markdown(response.choices[0].text)"},"cell_type":"code","id":"a10c3bb9-a91d-422f-a5a3-5d157b922e67","outputs":[{"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":" To protect global stability from inner or extraterrestrial threats."},"metadata":{},"execution_count":11}],"execution_count":11},{"source":"### Text Classification","metadata":{},"cell_type":"markdown","id":"c3964303-8a9f-49f4-96db-6de6fec922dd"},{"source":"prompt = \"\"\"Classify the text into neutral, negative or positive.\n\nText: I think the Avengers Endgame was an interesting movie..\n\nSentiment:\"\"\"\n\nresponse = get_completion(params, prompt)\nIPython.display.Markdown(response.choices[0].text)","metadata":{"executionCancelledAt":null,"executionTime":579,"lastExecutedAt":1716996922979,"lastExecutedByKernel":"0c23dd08-620d-4661-b77c-ef890c83f493","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"prompt = \"\"\"Classify the text into neutral, negative or positive.\n\nText: I think the Avengers Endgame was an interesting movie..\n\nSentiment:\"\"\"\n\nresponse = get_completion(params, prompt)\nIPython.display.Markdown(response.choices[0].text)"},"cell_type":"code","id":"f367a597-eb50-4d27-b604-f41695d18cf7","outputs":[{"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":" Positive"},"metadata":{},"execution_count":12}],"execution_count":12},{"source":"### Role Playing","metadata":{},"cell_type":"markdown","id":"94200ba7-c95d-4ee7-9589-55c1d11aabed"},{"source":"prompt = \"\"\"The following is a conversation with an AI research assistant. The assistant tone is technical and scientific.\n\nHuman: Hello, who are you?\nAI: Greeting! I am an AI research assistant. How can I help you today?\nHuman: Can you tell me about the big bang theory?\nAI:\"\"\"\n\nresponse = get_completion(params, prompt)\nIPython.display.Markdown(response.choices[0].text)\n","metadata":{"executionCancelledAt":null,"executionTime":1522,"lastExecutedAt":1716996956708,"lastExecutedByKernel":"0c23dd08-620d-4661-b77c-ef890c83f493","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"prompt = \"\"\"The following is a conversation with an AI research assistant. The assistant tone is technical and scientific.\n\nHuman: Hello, who are you?\nAI: Greeting! I am an AI research assistant. How can I help you today?\nHuman: Can you tell me about the big bang theory?\nAI:\"\"\"\n\nresponse = get_completion(params, prompt)\nIPython.display.Markdown(response.choices[0].text)\n"},"cell_type":"code","id":"6722feb6-cf4f-43ef-af77-3d7e36177f9c","outputs":[{"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":" The big bang theory is a scientific model that explains the origins of the universe. It proposes that the universe began as a singularity, a point of infinite density and temperature, and has been expanding and cooling ever since. This theory is supported by evidence such as the cosmic microwave background radiation and the observed redshift of galaxies. It is a widely accepted explanation for the formation and evolution of the universe. Is there anything specific you would like to know about the theory?"},"metadata":{},"execution_count":13}],"execution_count":13},{"source":"### Code Generation\n\nThe prompt instructs the language model to create a PostgreSQL query for all students in the Computer Science Department. It provides a hypothetical scenario with two tables (departments and students) and their columns.","metadata":{},"cell_type":"markdown","id":"18632856-2492-414f-9d57-a1b19cf4b236"},{"source":"prompt = \"\\\"\\\"\\\"\\nTable departments, columns = [DepartmentId, DepartmentName]\\nTable students, columns = [DepartmentId, StudentId, StudentName]\\nCreate a PostgreSQL query for all students in the Computer Science Department\\n\\\"\\\"\\\"\"\n\nresponse = get_completion(params, prompt)\nIPython.display.Markdown(response.choices[0].text)","metadata":{"executionCancelledAt":null,"executionTime":1087,"lastExecutedAt":1716996981742,"lastExecutedByKernel":"0c23dd08-620d-4661-b77c-ef890c83f493","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"prompt = \"\\\"\\\"\\\"\\nTable departments, columns = [DepartmentId, DepartmentName]\\nTable students, columns = [DepartmentId, StudentId, StudentName]\\nCreate a PostgreSQL query for all students in the Computer Science Department\\n\\\"\\\"\\\"\"\n\nresponse = get_completion(params, prompt)\nIPython.display.Markdown(response.choices[0].text)"},"cell_type":"code","id":"b3942589-b724-4836-aa77-092938c04a11","outputs":[{"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\nSELECT StudentName\nFROM students\nWHERE DepartmentId = (SELECT DepartmentId FROM departments WHERE DepartmentName = 'Computer Science')\nORDER BY StudentName;"},"metadata":{},"execution_count":14}],"execution_count":14},{"source":"### Reasoning ","metadata":{},"cell_type":"markdown","id":"278a5620-3012-405d-9982-5e3a58a47087"},{"source":"prompt = \"\"\"The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. \n\nSolve by breaking the problem into steps. First, identify the odd numbers, add them, and indicate whether the result is odd or even.\"\"\"\n\nresponse = get_completion(params, prompt)\nIPython.display.Markdown(response.choices[0].text)","metadata":{"executionCancelledAt":null,"executionTime":1391,"lastExecutedAt":1716997015677,"lastExecutedByKernel":"0c23dd08-620d-4661-b77c-ef890c83f493","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"prompt = \"\"\"The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. \n\nSolve by breaking the problem into steps. First, identify the odd numbers, add them, and indicate whether the result is odd or even.\"\"\"\n\nresponse = get_completion(params, prompt)\nIPython.display.Markdown(response.choices[0].text)"},"cell_type":"code","id":"ca1ded8e-7a31-4a14-99e2-af6c5cbd1f0c","outputs":[{"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\nStep 1: Identify the odd numbers in the group. \nOdd numbers: 15, 5, 13, 7, 1\n\nStep 2: Add up the odd numbers. \n15 + 5 + 13 + 7 + 1 = 41 \n\nStep 3: Determine if the result is odd or even. \nThe sum, 41, is an odd number."},"metadata":{},"execution_count":15}],"execution_count":15}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}