{"cells":[{"source":"# MODEL FINE-TUNING QUIZ","metadata":{},"cell_type":"markdown","id":"035bdada-a590-4e2a-b537-60df2091780c"},{"source":"### Import all neccessary library","metadata":{},"cell_type":"markdown","id":"afe820d8-13a3-44eb-9348-2acebf3bc4d5"},{"source":"import torch\nfrom transformers import AdamW, AutoTokenizer, AutoModelForSequenceClassification\nfrom datasets import load_dataset\nfrom transformers import DataCollatorWithPadding","metadata":{"executionCancelledAt":null,"executionTime":6107,"lastExecutedAt":1716899146571,"lastExecutedByKernel":"f11316cf-4140-4b9d-aef1-bdead958406f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import torch\nfrom transformers import AdamW, AutoTokenizer, AutoModelForSequenceClassification\nfrom datasets import load_dataset\nfrom transformers import DataCollatorWithPadding","outputsMetadata":{"0":{"height":164,"type":"stream"}}},"cell_type":"code","id":"f7355a9d-5b58-4b5a-a7ca-790524977022","outputs":[{"output_type":"stream","name":"stderr","text":"2024-05-28 12:25:44.932843: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"}],"execution_count":1},{"source":"### Some set up","metadata":{},"cell_type":"markdown","id":"410e1851-ff67-41b4-bd9d-9d54daeaf14e"},{"source":"checkpoint = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint)","metadata":{"executionCancelledAt":null,"executionTime":2972,"lastExecutedAt":1716899149545,"lastExecutedByKernel":"f11316cf-4140-4b9d-aef1-bdead958406f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"checkpoint = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint)","outputsMetadata":{"0":{"height":164,"type":"stream"}}},"cell_type":"code","id":"5e593845-76ab-47b9-87c0-3a2a465b2ef1","outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3553e55336c54bf9b69272b635e199d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b67cbe166e0042ad80ed61029c1942ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52253f69a5c84c37ae80c288de4ee9ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8233d8b837ed4299a734c08d4891979a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"570c452da74348e798472bf992d88681"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"}],"execution_count":2},{"source":"### Load the dataset","metadata":{},"cell_type":"markdown","id":"6778fb36-77b5-4265-86a4-7fb22fba81da"},{"source":"raw_datasets = load_dataset(\"glue\", \"mrpc\")\nraw_datasets","metadata":{"executionCancelledAt":null,"executionTime":2738,"lastExecutedAt":1716899152284,"lastExecutedByKernel":"f11316cf-4140-4b9d-aef1-bdead958406f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"raw_datasets = load_dataset(\"glue\", \"mrpc\")\nraw_datasets"},"cell_type":"code","id":"8fc5d0a1-fa74-44d1-9405-3285d04a5be7","outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/35.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b9a974ef6374f18a2351abd7b3cb23d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/649k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"388a32963c1b4815a9c21d16fe2ea817"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/75.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89355af0cd4e4f2bbf7fc5c4e26f2dcc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/308k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab07ac397ce24ba2924c50e497680561"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/3668 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0eebbe5d5b9b4dce892485ce38ed3aea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/408 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18d062c3c34e4a7e8a8f0d464caeb450"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1725 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85b9d9f572fd4d96b3a3cea50b4251bb"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 3668\n    })\n    validation: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 408\n    })\n    test: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 1725\n    })\n})"},"metadata":{},"execution_count":3}],"execution_count":3},{"source":"## Questions and Code Answers","metadata":{},"cell_type":"markdown","id":"bcf35670-a9d3-4965-8253-ac67c67f8c8f"},{"source":"##### What are the correct features of the test dataset saved to the raw_test_variable earlier on?","metadata":{},"cell_type":"markdown","id":"d7ee030d-95b0-4a8e-a910-11fb75eba0c0"},{"source":"raw_test_variable = raw_datasets[\"test\"].features\nraw_test_variable","metadata":{"executionCancelledAt":null,"executionTime":445,"lastExecutedAt":1716899152729,"lastExecutedByKernel":"f11316cf-4140-4b9d-aef1-bdead958406f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"raw_test_variable = raw_datasets[\"test\"].features\nraw_test_variable"},"cell_type":"code","id":"a6ec780f-8eb0-4fe9-a5b6-64718ed82550","outputs":[{"output_type":"execute_result","data":{"text/plain":"{'sentence1': Value(dtype='string', id=None),\n 'sentence2': Value(dtype='string', id=None),\n 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None),\n 'idx': Value(dtype='int32', id=None)}"},"metadata":{},"execution_count":4}],"execution_count":4},{"source":"##### Extracts and displays the first data sample from the 'test' split of the Microsoft Research Paraphrase Corpus (MRPC) dataset stored in the variable 'raw_test_dataset' obtained from the previously loaded dataset. \n\n**What is the content of the first sentence?**","metadata":{},"cell_type":"markdown","id":"5498e226-c566-4c68-afd2-8e845026f291"},{"source":"raw_test_dataset = raw_datasets[\"test\"]\nraw_test_dataset[0][\"sentence1\"]","metadata":{"executionCancelledAt":null,"executionTime":124,"lastExecutedAt":1716899152853,"lastExecutedByKernel":"f11316cf-4140-4b9d-aef1-bdead958406f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"raw_test_dataset = raw_datasets[\"test\"]\nraw_test_dataset[0][\"sentence1\"]"},"cell_type":"code","id":"e788c9dd-bbe5-4d32-b392-26907b9fa8d1","outputs":[{"output_type":"execute_result","data":{"text/plain":"\"PCCW 's chief operating officer , Mike Butcher , and Alex Arena , the chief financial officer , will report directly to Mr So .\""},"metadata":{},"execution_count":5}],"execution_count":5},{"source":"##### Write a code snippet that uses a tokenizer to process the sentence pairs from the 'train' split of the Microsoft Research Paraphrase Corpus (MRPC) dataset. The code should perform tokenization, enable padding, and truncation for the sentence pairs from sentence1 and sentence2. \n\n#### What is the number of tokens when you access the 3 content of the tokenized sentence1 after implementing padding and truncation?","metadata":{},"cell_type":"markdown","id":"80cd40f5-b751-4a71-8c2f-17cbfbcb0f2f"},{"source":"def tokenize_function(example):\n    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation = True)\n\ntokenized_datasets = raw_datasets.map(tokenize_function, batched = True)\n\ndata_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n\nsamples = tokenized_datasets[\"train\"][:3]\nsamples = {k: v for k, v in samples.items() if k not in [\"idx\", \"sentence1\", \"sentence2\"]}\n[len(x) for x in samples[\"input_ids\"]][0]","metadata":{"executionCancelledAt":null,"executionTime":664,"lastExecutedAt":1716899153517,"lastExecutedByKernel":"f11316cf-4140-4b9d-aef1-bdead958406f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def tokenize_function(example):\n    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation = True)\n\ntokenized_datasets = raw_datasets.map(tokenize_function, batched = True)\n\ndata_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n\nsamples = tokenized_datasets[\"train\"][:3]\nsamples = {k: v for k, v in samples.items() if k not in [\"idx\", \"sentence1\", \"sentence2\"]}\n[len(x) for x in samples[\"input_ids\"]][0]"},"cell_type":"code","id":"7fa0c2f6-8420-41b0-a000-2218a598b066","outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3668 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"958b81bf1bb74b67802a5360b6eb029b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/408 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50f34875ebb04ab6818397ead27f5198"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1725 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94efe82afc764f71a08dc538682e4d94"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":"50"},"metadata":{},"execution_count":6}],"execution_count":6},{"source":"##### Extracts and displays the third data sample from the 'train' split of the Microsoft Research Paraphrase Corpus (MRPC) dataset stored in the variable 'raw_train_dataset' obtained from the previously loaded dataset. \n\n#### What is the content of the second sentence?","metadata":{},"cell_type":"markdown","id":"308a7822-b2e1-467d-bc62-4763c02fc41c"},{"source":"raw_train_dataset = raw_datasets[\"train\"]\nraw_train_dataset[2][\"sentence2\"]","metadata":{"executionCancelledAt":null,"executionTime":194,"lastExecutedAt":1716899153711,"lastExecutedByKernel":"f11316cf-4140-4b9d-aef1-bdead958406f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"raw_train_dataset = raw_datasets[\"train\"]\nraw_train_dataset[2][\"sentence2\"]"},"cell_type":"code","id":"2e46838f-6223-4dd3-861f-59eba99c6a3a","outputs":[{"output_type":"execute_result","data":{"text/plain":"\"On June 10 , the ship 's owners had published an advertisement on the Internet , offering the explosives for sale .\""},"metadata":{},"execution_count":7}],"execution_count":7},{"source":"##### How many pairs of sentences are there in the training set of the MRPC dataset?","metadata":{},"cell_type":"markdown","id":"7d55ffca-ad8a-4b11-8658-c90cf6abab6c"},{"source":"raw_train_dataset.num_rows","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1716899153766,"lastExecutedByKernel":"f11316cf-4140-4b9d-aef1-bdead958406f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"raw_train_dataset.num_rows"},"cell_type":"code","id":"be56d1ef-aa07-41bf-bc2b-d89d0bdb2c8f","outputs":[{"output_type":"execute_result","data":{"text/plain":"3668"},"metadata":{},"execution_count":8}],"execution_count":8},{"source":"##### Preprocessing the dataset: Write a code snippet that uses a tokenizer to process the sentence pairs from the 'train' split of the Microsoft Research Paraphrase Corpus (MRPC) dataset. The code should perform tokenization for the sentence pairs from sentence1 and sentence2. \n#### What is the number of tokens when you access the 3 content of the tokenized sentence1?","metadata":{},"cell_type":"markdown","id":"f842dc0c-c4f2-4a5d-9a0f-270be9adb315"},{"source":"def tokenize_function(example):\n    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation = True)\n\ntokenized_train_dataset = raw_train_dataset.map(tokenize_function, batched = True)\n\nsamples = tokenized_train_dataset[:3]\nlen(samples[\"input_ids\"][2])","metadata":{"executionCancelledAt":null,"executionTime":376,"lastExecutedAt":1716899163730,"lastExecutedByKernel":"f11316cf-4140-4b9d-aef1-bdead958406f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def tokenize_function(example):\n    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation = True)\n\ntokenized_train_dataset = raw_train_dataset.map(tokenize_function, batched = True)\n\nsamples = tokenized_train_dataset[:3]\nlen(samples[\"input_ids\"][2])"},"cell_type":"code","id":"c304f399-d2be-4ae2-845b-11e8726b2e10","outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3668 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ad25ceb05a34350b8d901b5ddb3bd5f"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":"47"},"metadata":{},"execution_count":9}],"execution_count":9}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}